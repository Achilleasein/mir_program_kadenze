{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cover Song Detection and Beat-Synchronous Chroma \n",
    "### George Tzanetakis, University of Victoria\n",
    "\n",
    "In this notebook, we explore a simple method for cover song detection using a beat-synchronous \n",
    "chroma representation. This is a toy example used to become familiar with the key concepts. An \n",
    "actual cover song detection system would be more complicated. \n",
    "\n",
    "We will consider a small toy collection of 5 recordings. These consists \n",
    "of the song Dreamer by the group Supertramp. The second recording \n",
    "is the same as the first but slowed down. The third recording \n",
    "is a different performance of the same song. The fourth recording \n",
    "is the song Goodbye Stranger also by Supertramp that has somewhat \n",
    "similar instrumentation but is a different song. Finally the last recording \n",
    "is the beautiful jazz balad Naima by John Coltrane. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io.wavfile as wav\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import pyrubberband as pyrb\n",
    "import scipy\n",
    "\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=DeprecationWarning)\n",
    "    import librosa, librosa.display\n",
    "\n",
    "def load_wav(fname): \n",
    "    srate, audio = wav.read(fname)\n",
    "    audio = audio.astype(np.float32) / 32767.0 \n",
    "    audio = (0.9 / np.max(audio)) * audio\n",
    "    # convert to mono \n",
    "    if (len(audio.shape) == 2):\n",
    "        audio = (audio[:, 0] + audio[:, 1]) / 2\n",
    "    return (audio,srate) \n",
    "\n",
    "\n",
    "dreamer,srate = load_wav('dreamer.wav')\n",
    "dreamer_live, srate = load_wav('dreamer_live.wav')\n",
    "dreamer_slow = pyrb.time_stretch(dreamer, srate, 0.75)\n",
    "goodbye_stranger, srate = load_wav('goodbye_stranger.wav')\n",
    "naima,srate = load_wav('naima.wav')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(dreamer,rate=srate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(dreamer_live,rate=srate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(dreamer_slow, rate=srate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(goodbye_stranger, rate=srate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate a chromagram using a CQT transform that represents the energy in different pitch classes across time. To calculate a beat-synchronous representation first the beats are extracted. Multiple chroma vectors correspond to each beat so we take their median to aggregate them. The resulting representation theoretically is tempo invariant. Even though visually it is not obvious - notice the significant reduction in the sizes of the chromagram matrices when beat-syncronization is used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_chromagram(y):\n",
    "    y = y[0:8000000]\n",
    "    C = librosa.feature.chroma_cqt(y, sr=srate, bins_per_octave=12, norm=2)\n",
    "    \n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    # Display the chromagram: the energy in each chromatic pitch class as a function of time\n",
    "    # To make sure that the colors span the full range of chroma values, set vmin and vmax\n",
    "    librosa.display.specshow(C, sr=srate, x_axis='time', y_axis='chroma', vmin=0, vmax=1)\n",
    "    plt.title('Chromagram')\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "\n",
    "    # extract beats \n",
    "    tempo, beats = librosa.beat.beat_track(y, sr=srate)\n",
    "    C_sync = librosa.util.sync(C, beats, aggregate=np.median)\n",
    "\n",
    "    librosa.display.specshow(C_sync, y_axis='chroma', sr=srate,vmin=0.0, vmax=1.0, x_axis='time', \n",
    "                         x_coords=librosa.frames_to_time(librosa.util.fix_frames(beats), sr=srate))\n",
    "    plt.title('Beat Synchronous Chromagram')\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # for the beat-synchronous use 280 beats\n",
    "    return C,C_sync[:,0:280] \n",
    "    \n",
    "    \n",
    "dreamer_cqt, dreamer_bcqt = plot_chromagram(dreamer)\n",
    "dreamer_slow_cqt, dreamer_slow_bcqt = plot_chromagram(dreamer_slow)\n",
    "dreamer_live_cqt, dreamer_live_bcqt = plot_chromagram(dreamer_live)\n",
    "goodbye_stranger_cqt, goodbye_stranger_bcqt = plot_chromagram(goodbye_stranger)\n",
    "naima_cqt, naima_bcqt = plot_chromagram(naima)\n",
    "\n",
    "\n",
    "print(dreamer_cqt.shape, dreamer_bcqt.shape)\n",
    "print(dreamer_slow_cqt.shape, dreamer_slow_bcqt.shape)\n",
    "print(dreamer_live_cqt.shape, dreamer_live_bcqt.shape)\n",
    "print(goodbye_stranger_cqt.shape, goodbye_stranger_bcqt.shape)\n",
    "print(naima_cqt.shape, naima_bcqt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cqt_list = [dreamer_cqt, dreamer_slow_cqt, dreamer_live_cqt, goodbye_stranger_cqt, naima_cqt]\n",
    "\n",
    "\n",
    "sim_matrix = np.zeros([5,5])\n",
    "for (i,s1) in enumerate(cqt_list):\n",
    "    for (j,s2) in enumerate(cqt_list):\n",
    "        b = np.mean(np.sum(s1 * s2,axis=0))\n",
    "        sim_matrix[i,j] = b\n",
    "print(sim_matrix)\n",
    "\n",
    "plt.imshow(sim_matrix)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cqt_list = [dreamer_cqt, dreamer_slow_cqt, dreamer_live_cqt, goodbye_stranger_cqt, naima_cqt]\n",
    "bcqt_list = [dreamer_bcqt, dreamer_slow_bcqt, dreamer_live_bcqt, goodbye_stranger_bcqt, naima_bcqt]\n",
    "\n",
    "\n",
    "sim_matrix = np.zeros([5,5])\n",
    "for (i,s1) in enumerate(bcqt_list):\n",
    "    for (j,s2) in enumerate(bcqt_list):\n",
    "        b = np.mean(np.sum(s1 * s2,axis=0))\n",
    "        sim_matrix[i,j] = b\n",
    "print(sim_matrix)\n",
    "\n",
    "plt.imshow(sim_matrix)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
